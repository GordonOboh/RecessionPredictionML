
\section{Project Implementation}

\begin{comment}
\begin{itemize}
    \item \hlgreen{System Architecture: For technical projects, outline the architecture or structure of your system.}
    \item \hlgreen{Development Process: Discuss the steps you took to build, test, and deploy your solution.}
    \item \hlgreen{Technologies Used: Mention programming languages, frameworks, or tools employed.}
\end{itemize}
\end{comment}





%#################################################################

\subsection{System Architecture}

The overarching architecture of this project was systematically structured into four distinct phases: data preparation, model testing and validation, analysis of model results, and the implementation of forecasting methodologies. This sequential framework ensured a logical progression from raw data to actionable insights regarding recession indicators. 
Initially, the process focused on the meticulous acquisition, cleaning, and transformation of raw datasets, specifically those identified as crucial recession indicators through prior research and literature reviews. Subsequently, a selection of machine learning models, chosen for their theoretical applicability to time-series analysis and predictive analytics, underwent rigorous testing and validation against historical data. The performance metrics derived from these models were then meticulously recorded and analyzed to discern their efficacy and reliability. The final phase involved leveraging the insights from the best-performing models to generate future forecasts for economic recession, providing a forward-looking perspective based on empirical evidence.


\subsection{Development Process}

The development process for this study commenced with the critical steps of initial data cleaning and subsequent importation, establishing a robust foundation for the analytical procedures. This foundational stage ensured data quality and consistency, which are paramount for reliable model performance. The second, and most extensive, phase involved a multi-faceted analytical approach. This included monitoring key economic indicators such as the 10-year-minus-2-year Treasury yield spread and the 10-year-minus-3-month Treasury yield spread, with careful consideration given to varying average day intervals to capture different temporal dynamics. The Treasury yield data was systematically split into training, validation, and testing sets to ensure unbiased model evaluation. Furthermore, the process entailed generating detailed comparisons between actual historical data and the curves predicted by linear regression models, providing a visual and statistical assessment of model fit. Finally, various forecasting models were applied, and their respective results were thoroughly analyzed to identify patterns and predictive capabilities.
To rigorously evaluate the performance of the diverse models employed, a comprehensive set of reference metrics was utilized. These included precision, recall, F1-score, and the Area Under the Receiver Operating Characteristic curve (\AUCone score). Each of these metrics provided a distinct perspective on model effectiveness, particularly in identifying and predicting recessionary periods. Precision assessed the accuracy of positive predictions, recall measured the model's ability to identify all actual positive cases, the F1-score offered a balanced measure of both, and the \AUCone score provided an aggregate measure of performance across all possible classification thresholds. Ultimately, the model demonstrating the most superior performance across these critical evaluation metrics was selected and implemented for forecasting future recessionary periods within this project, serving as the primary predictive tool.


\subsection{Technologies Used}

All experimental procedures and analytical tasks within this project were conducted in an offline, notebook-based environment, chosen for its flexibility, reproducibility, and iterative development capabilities. The entire workflow, encompassing structured preprocessing, meticulous feature engineering, comprehensive model training, and rigorous evaluation steps, was implemented as modular components. The core programming language utilized for all computational tasks was Python, leveraging its extensive libraries for data manipulation, statistical analysis, and machine learning. Jupyter Notebook served as the primary interactive development environment, facilitating code execution, visualization, and documentation in an integrated format. For version control and collaborative development, GitHub was employed, ensuring efficient tracking of changes and seamless teamwork. Finally, the MS Office Suite was instrumental for generating comprehensive reports, creating professional presentations, and managing project documentation, thereby supporting the communication and dissemination of the project's findings.


\subsection{LSTM Model Architecture}

The Long Short-Term Memory (LSTM) models employed in this study are configured with $1...n$ layers, where the number of layers and their respective hidden units are determined by the model name. For example, \texttt{LSTM\_4} denotes a single-layer LSTM with 4 units, while \texttt{LSTM\_4\_2} denotes a two-layer LSTM with 4 units in the first layer and 2 units in the second layer.

Each model terminates with a dense output layer using a sigmoid activation function to map the final hidden state to a binary classification. Dropout regularization with a rate of 0.3 is applied after each LSTM layer to mitigate overfitting. Training is performed using the Adam optimizer and a binary focal loss function (equation (~\ref{eq:binary_focal_loss_function})), parameterized by $\gamma = 2.0$,  $\alpha$(equation (~\ref{eq:alpha})) and class weight calculations (equation (~\ref{eq:class_weight}))  to address class imbalance. 
Model performance is evaluated using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC)
%}

%both the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) and the Area Under the Precision-Recall Curve (AUC-PR).

The following LSTM variants were implemented:

\begin{itemize}
\item \texttt{LSTM\_4}, \texttt{LSTM\_8}: Single-layer LSTM models with 4 or 8 hidden units.
\item \texttt{LSTM\_4\_4}, \texttt{LSTM\_8\_4}, \texttt{LSTM\_8\_8}: Two-layer LSTM models with corresponding hidden unit configurations.
\end{itemize}

\begin{comment}


\begin{equation}
\alpha = \frac{\omega_1}{\omega_0 + \omega_1} %\tag{1}
\label{eq:alpha}
\end{equation}

where $\omega_0$ and $\omega_1$ are the class weights for the majority (no recession) and minority (recession) classes, respectively.

\begin{equation}
\omega_c = \frac{n_{samples}}{n_{classes} \cdot n_c}
\label{eq:class_weight}
\end{equation}

\noindent
where:
\vspace{-9pt}
\begin{itemize} [itemsep = -6pt]
    \item $c = $ class 0 or class 1
    \item $\omega_c = $ weight for class $c$
    \item $n_{samples} = $ total number of training samples
    \item $n_{classes} = $ number of distinct classes
    \item $n_c = $ number of samples in class $c$
\end{itemize}


\begin{equation}
L_{\text{focal}}(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)
\label{eq:binary_focal_loss_function}
\end{equation}

where $p_t$ is the predicted probability of the true class.

\end{comment}

