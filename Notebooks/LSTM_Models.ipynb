{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98dc1aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For notebooks â€” get the current working directory\n",
    "notebook_dir = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "# Then import your module\n",
    "#import Utils.functions as data_viz\n",
    "import Utils.file_io as file_io\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9826407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, average_precision_score, balanced_accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.metrics import AUC, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdef7687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from /workspaces/RecessionPredictionML/Notebooks/Dataset/data_features_daily.csv\n",
      "DataFrame loaded from /workspaces/RecessionPredictionML/Notebooks/Dataset/data_features_weekly.csv\n",
      "DataFrame loaded from /workspaces/RecessionPredictionML/Notebooks/Dataset/data_features_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "#File imports and initialization\n",
    "#classifier_models = ['logistic', 'xgb', 'balanced_rf', 'easy_ensemble', 'rf']\n",
    "\n",
    "file_path = f\"{project_dir}/Notebooks/Dataset/data_features\"\n",
    "\n",
    "df_features_daily = file_io.input_csv(f\"{file_path}_daily\")\n",
    "df_features_weekly = file_io.input_csv(f\"{file_path}_weekly\")\n",
    "df_features_monthly = file_io.input_csv(f\"{file_path}_monthly\")\n",
    "\n",
    "#recessions = pd.read_csv(f\"{project_dir}/Dataset/recession_periods.csv\")\n",
    "#recessions = file_io.input_csv(f\"{project_dir}/Dataset/recession_periods\")\n",
    "recessions = pd.read_csv(f\"{project_dir}/Dataset/recession_periods.csv1\")\n",
    "\n",
    "dict_features = {'Daily': df_features_daily,\n",
    "                 'Weekly': df_features_weekly,\n",
    "                 'Monthly': df_features_monthly\n",
    "} \n",
    "\n",
    "train_test_split = pd.to_datetime('2015-01-01')\n",
    "split_at = train_test_split\n",
    "\n",
    "export_config = {'Print Out For all models': \n",
    "                  {'save': False},\n",
    "                 'Save Probability Plots as PNG': \n",
    "                  {'save': False},\n",
    "                 'Export AUC Report to CSV': \n",
    "                  {'save': False}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29facf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor\n",
    "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        eps = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        \n",
    "        cross_entropy = - (y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
    "\n",
    "        loss = alpha_factor * modulating_factor * cross_entropy\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "def make_sequences(X, y=None, seq_len=12):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        X_seq.append(X.iloc[i:i+seq_len].values)\n",
    "        if y is not None:\n",
    "            y_seq.append(y.iloc[i+seq_len])\n",
    "    X_seq = np.array(X_seq)\n",
    "    return (X_seq, np.array(y_seq)) if y is not None else (X_seq, None)\n",
    "\n",
    "def get_class_weight(y_train):\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "    return class_weights_dict, alpha\n",
    "    \n",
    "    \n",
    "def scaling_features(train,test, scaler_func = StandardScaler()):\n",
    "    scaler = scaler_func\n",
    "    X_train = train\n",
    "    X_test = test\n",
    "    n_train, seq_len, n_feat = X_train.shape\n",
    "    n_test,      _   ,  _    = X_test.shape\n",
    "    if scaler_func is None:\n",
    "        return X_train, X_test, seq_len, n_feat\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train.reshape(-1, n_feat)).reshape(n_train, seq_len, n_feat)\n",
    "    X_test_scaled  = scaler.transform    (X_test.reshape(-1, n_feat)).reshape(n_test, seq_len, n_feat)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, seq_len, n_feat\n",
    "\n",
    "def layer_sizes(str_var):\n",
    "    str_var = 'LSTM_4_2'\n",
    "    parts = str_var.split('_')\n",
    "    int_list = [int(x) for x in parts[1:]]\n",
    "    model_type = parts[0]\n",
    "    return int_list, model_type\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c40b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5992b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#X_train_scaled, X_test_scaled, seq_len, n_feat = scaling_features(X_train, X_test) #one time calculation per time_freq?\n",
    "\n",
    "#class_weights_dict, alpha = compute_class_weight(y_train) # one time calculation per time_freq?\n",
    "\n",
    "def LSTM_Model_init(model_name, seq_len, n_feat, alpha):\n",
    "\n",
    "    layer_size, model_type = layer_sizes(model_name)\n",
    "\n",
    "    is_bi = model_type.upper().startswith(\"BILSTM\")\n",
    "\n",
    "    #Build model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(seq_len, n_feat)))\n",
    "    \n",
    "\n",
    "    for i, units in enumerate(layer_size):\n",
    "        return_seq = (i < len(layer_size) - 1)\n",
    "        lstm_layer = LSTM(units, return_sequences=return_seq)\n",
    "\n",
    "        if is_bi:\n",
    "            # wrap in Bidirectional\n",
    "            model.add(Bidirectional(lstm_layer))\n",
    "        else:\n",
    "            model.add(lstm_layer)\n",
    "        \n",
    "        model.add(Dropout(0.3))\n",
    "    # stuff\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=binary_focal_loss(gamma=2.0, alpha=alpha),\n",
    "        #metrics=[\"accuracy\"]\n",
    "        metrics=[#\"Precision\", \"Recall\", #\"AUC\"]\n",
    "                    AUC(name='AUC-ROC'),\n",
    "                    AUC(name='AUC-PR', curve='PR')]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "#early_stop = EarlyStopping(monitor=\"val_Recall\", patience=10, restore_best_weights=True, mode='max')\n",
    "\n",
    "def LSTM_Model_train(train, early_stop, model, class_weights, verbose = 0):\n",
    "    X_train_scaled, y_train = train[0], train[1]\n",
    "    callback_list = [early_stop] if early_stop is not None else []\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=50, batch_size=32,\n",
    "        callbacks=callback_list,\n",
    "        class_weight=class_weights,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    print('Done with training')\n",
    "    epochs = len(history.history['loss'])\n",
    "    return model, epochs\n",
    "\n",
    "def LSTM_Model_evaluate(model, verbose=0, threshold = None):\n",
    "\n",
    "    \n",
    "\n",
    "    X_all_scaled = np.concatenate([X_train_scaled, X_test_scaled], axis=0) #pd.concat([X_train_scaled, X_test_scaled])\n",
    "    probs_all = model.predict(X_all_scaled, verbose=verbose).reshape(-1)\n",
    "    n_test = len(y_test)\n",
    "    probs_pred = probs_all[-n_test:]\n",
    "    if threshold is None:\n",
    "        threshold = 0.001\n",
    "    y_pred = (probs_pred >= threshold).astype(int)\n",
    "\n",
    "    #precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=[\"No Recession\", \"Recession\"], output_dict=True, zero_division=0)\n",
    "    #report[\"auc_pr\"] = auc(recall, precision)\n",
    "    report[\"ap_score\"]=  average_precision_score(y_test, probs_all)\n",
    "    report[\"auc_roc\"]= roc_auc_score(y_test, probs_all)\n",
    "\n",
    "    epochs = len(history.history['loss'])\n",
    "    return probs_all, report, epochs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7f04462",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_models = ['LSTM_4_2', 'LSTM_4_4']\n",
    "LSTM_results = {}\n",
    "early_stop = EarlyStopping(monitor=\"val_Recall\", patience=10, restore_best_weights=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dda9c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_4_2\n",
      "Done with Init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_Recall` which is not available. Available metrics are: AUC-PR,AUC-ROC,loss,val_AUC-PR,val_AUC-ROC,val_loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2756, 11535]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m model_init = LSTM_Model_init(model_name, seq_len, n_feat, alpha)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDone with Init\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m probs, report, epochs = \u001b[43mLSTM_Model_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m LSTM_results[time_freq][model_name][\u001b[33m'\u001b[39m\u001b[33mprobs\u001b[39m\u001b[33m'\u001b[39m] = probs\n\u001b[32m     29\u001b[39m LSTM_results[time_freq][model_name][\u001b[33m'\u001b[39m\u001b[33mreport\u001b[39m\u001b[33m'\u001b[39m] = report\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mLSTM_Model_evaluate\u001b[39m\u001b[34m(train, test, model, early_stop, class_weights, verbose, threshold)\u001b[39m\n\u001b[32m     82\u001b[39m report = classification_report(y_test, y_pred, target_names=[\u001b[33m\"\u001b[39m\u001b[33mNo Recession\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRecession\u001b[39m\u001b[33m\"\u001b[39m], output_dict=\u001b[38;5;28;01mTrue\u001b[39;00m, zero_division=\u001b[32m0\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m#report[\"auc_pr\"] = auc(recall, precision)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m report[\u001b[33m\"\u001b[39m\u001b[33map_score\u001b[39m\u001b[33m\"\u001b[39m]=  \u001b[43maverage_precision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m report[\u001b[33m\"\u001b[39m\u001b[33mauc_roc\u001b[39m\u001b[33m\"\u001b[39m]= roc_auc_score(y_test, probs_all)\n\u001b[32m     87\u001b[39m epochs = \u001b[38;5;28mlen\u001b[39m(history.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:263\u001b[39m, in \u001b[36maverage_precision_score\u001b[39m\u001b[34m(y_true, y_score, average, pos_label, sample_weight)\u001b[39m\n\u001b[32m    258\u001b[39m     y_true = label_binarize(y_true, classes=present_labels)\n\u001b[32m    260\u001b[39m average_precision = partial(\n\u001b[32m    261\u001b[39m     _binary_uninterpolated_average_precision, pos_label=pos_label\n\u001b[32m    262\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43maverage_precision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/metrics/_base.py:69\u001b[39m, in \u001b[36m_average_binary_score\u001b[39m\u001b[34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m     72\u001b[39m y_true = check_array(y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:224\u001b[39m, in \u001b[36maverage_precision_score.<locals>._binary_uninterpolated_average_precision\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_binary_uninterpolated_average_precision\u001b[39m(\n\u001b[32m    222\u001b[39m     y_true, y_score, pos_label=\u001b[32m1\u001b[39m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     precision, recall, _ = \u001b[43mprecision_recall_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# Return the step function integral\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# The following works because the last entry of precision is\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;66;03m# guaranteed to be 1, as returned by precision_recall_curve.\u001b[39;00m\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Due to numerical error, we can get `-0.0` and we therefore clip it.\u001b[39;00m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[32m0.0\u001b[39m, -np.sum(np.diff(recall) * np.array(precision)[:-\u001b[32m1\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:189\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1005\u001b[39m, in \u001b[36mprecision_recall_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight, drop_intermediate, probas_pred)\u001b[39m\n\u001b[32m    996\u001b[39m     warnings.warn(\n\u001b[32m    997\u001b[39m         (\n\u001b[32m    998\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprobas_pred was deprecated in version 1.5 and will be removed in 1.7.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1001\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   1002\u001b[39m     )\n\u001b[32m   1003\u001b[39m     y_score = probas_pred\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m fps, tps, thresholds = \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) > \u001b[32m2\u001b[39m:\n\u001b[32m   1010\u001b[39m     \u001b[38;5;66;03m# Drop thresholds corresponding to points where true positives (tps)\u001b[39;00m\n\u001b[32m   1011\u001b[39m     \u001b[38;5;66;03m# do not change from the previous or subsequent point. This will keep\u001b[39;00m\n\u001b[32m   1012\u001b[39m     \u001b[38;5;66;03m# only the first and last point for each tps value. All points\u001b[39;00m\n\u001b[32m   1013\u001b[39m     \u001b[38;5;66;03m# with the same tps value have the same recall and thus x coordinate.\u001b[39;00m\n\u001b[32m   1014\u001b[39m     \u001b[38;5;66;03m# They appear as a vertical line on the plot.\u001b[39;00m\n\u001b[32m   1015\u001b[39m     optimal_idxs = np.where(\n\u001b[32m   1016\u001b[39m         np.concatenate(\n\u001b[32m   1017\u001b[39m             [[\u001b[38;5;28;01mTrue\u001b[39;00m], np.logical_or(np.diff(tps[:-\u001b[32m1\u001b[39m]), np.diff(tps[\u001b[32m1\u001b[39m:])), [\u001b[38;5;28;01mTrue\u001b[39;00m]]\n\u001b[32m   1018\u001b[39m         )\n\u001b[32m   1019\u001b[39m     )[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:820\u001b[39m, in \u001b[36m_binary_clf_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m y_true = column_or_1d(y_true)\n\u001b[32m    822\u001b[39m y_score = column_or_1d(y_score)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [2756, 11535]"
     ]
    }
   ],
   "source": [
    "for time_freq, df in dict_features.items():\n",
    "    X = df.drop(columns='recession')\n",
    "    y = df['recession'] \n",
    "\n",
    "    # Train-test split\n",
    "    #split_at = pd.to_datetime('2015-01-01')\n",
    "    X_train, X_test = X[X.index < split_at], X[X.index >= split_at]\n",
    "    y_train, y_test = y[y.index < split_at].astype(int), y[y.index >= split_at].astype(int)\n",
    "\n",
    "    # Convert to sequences\n",
    "    seq_len = 32\n",
    "    X_train_seq, y_train_seq = make_sequences(X_train, y_train, seq_len)\n",
    "    X_test_seq, y_test_seq = make_sequences(X_test, y_test, seq_len)\n",
    "\n",
    "    X_train_scaled, X_test_scaled, _, n_feat = scaling_features(X_train_seq, X_test_seq) #one time calculation per time_freq?\n",
    "    class_weights_dict, alpha = get_class_weight(y_train_seq) # one time calculation per time_freq?\n",
    "\n",
    "    LSTM_results[time_freq] = {}\n",
    "    for model_name in LSTM_models:\n",
    "        LSTM_results[time_freq][model_name] = {}\n",
    "        print(model_name)\n",
    "        model_init = LSTM_Model_init(model_name, seq_len, n_feat, alpha)\n",
    "        print('Done with Init')\n",
    "        probs, report, epochs = LSTM_Model_evaluate(train = [X_train_scaled,y_train_seq], test = [X_test_scaled, y_test_seq],\n",
    "                                  model = model_init, early_stop = early_stop, class_weights = class_weights_dict, \n",
    "                                  verbose=0, threshold = None)\n",
    "        \n",
    "        LSTM_results[time_freq][model_name]['probs'] = probs\n",
    "        LSTM_results[time_freq][model_name]['report'] = report\n",
    "        LSTM_results[time_freq][model_name]['epochs'] = epochs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
